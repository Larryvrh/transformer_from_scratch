{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:24:33.027648494Z",
     "start_time": "2023-11-02T06:24:31.896886444Z"
    }
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "from tokenizers import TRIETokenizerFast\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from dataloader import DatasetWriter, SingleDatasetReader\n",
    "from typing import *\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "tokenizer = TRIETokenizerFast('llama_vocab_pruned_32k.json')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:24:41.102624012Z",
     "start_time": "2023-11-02T06:24:33.028647189Z"
    }
   },
   "id": "1d265892fe30a6d4"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "alpaca_gpt = datasets.load_dataset('vicgalle/alpaca-gpt4', cache_dir='./corpus')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:24:42.631239942Z",
     "start_time": "2023-11-02T06:24:41.102569049Z"
    }
   },
   "id": "794851e03446e7ea"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "airoboros = datasets.load_dataset('jondurbin/airoboros-2.2.1', cache_dir='./corpus')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:24:44.256605821Z",
     "start_time": "2023-11-02T06:24:42.629683830Z"
    }
   },
   "id": "25f21ce32b9a3211"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "wizardlm = datasets.load_dataset('WizardLM/WizardLM_evol_instruct_V2_196k', cache_dir='./corpus')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:24:46.337323077Z",
     "start_time": "2023-11-02T06:24:44.261816845Z"
    }
   },
   "id": "14ddd1dc80bb3646"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def preview_chunk(token_ids, attn_mask, loss_mask):\n",
    "    unique_mask = [i for i in set(attn_mask) if i != 0]\n",
    "    print(f'Total {len(unique_mask)} dialogues within chunk.')\n",
    "    for m in unique_mask:\n",
    "        print(f'Dialogue index {m}')\n",
    "        dialogue_token_ids = [token_ids[i] for i in range(len(token_ids)) if attn_mask[i] == m]\n",
    "        dialogue_token_ids_loss = [token_ids[i] for i in range(len(token_ids)) if attn_mask[i] == m and loss_mask[i] == 1]\n",
    "        print('Full text:')\n",
    "        print(tokenizer.decode(dialogue_token_ids))\n",
    "        print('-' * 80)\n",
    "        print('Loss text:')\n",
    "        print(tokenizer.decode(dialogue_token_ids_loss))\n",
    "        print('=' * 80)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:24:46.351517189Z",
     "start_time": "2023-11-02T06:24:46.343561097Z"
    }
   },
   "id": "308c5261ca3e996a"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def dialogues_to_chunks(dialogues: List[List[Tuple[str, str]]], chunk_length: int, max_message_length: int, overlap_count: int):\n",
    "    assert max_message_length * overlap_count < chunk_length, 'max_message_length * overlap_count >= chunk_size can cause infinite loop'\n",
    "\n",
    "    skip_dialogue_count = 0\n",
    "\n",
    "    start_tokens = tokenizer.encode('<s>A chat between User and Assistant.\\n')\n",
    "\n",
    "    mask_index = 0\n",
    "    token_ids, attn_mask, loss_mask = [], [], []\n",
    "\n",
    "    for dial in tqdm(dialogues):\n",
    "        dial_encoded = [(m[0], tokenizer.encode(f'{m[0]}:{m[1]}' + {'User': '\\n', 'Assistant': '</s>\\n'}[m[0]])) for m in dial]\n",
    "        if any(len(m[1]) > max_message_length for m in dial_encoded):\n",
    "            skip_dialogue_count += 1\n",
    "            continue\n",
    "\n",
    "        mask_index += 1\n",
    "        if chunk_length - len(token_ids) <= len(start_tokens):\n",
    "            pad_length = chunk_length - len(token_ids)\n",
    "            token_ids += [0 for _ in range(pad_length)]\n",
    "            attn_mask += [chunk_length + 1 for _ in range(pad_length)]  # use standalone index for padding mask to avoid \"void attention\"\n",
    "            loss_mask += [0 for _ in range(pad_length)]\n",
    "            assert len(token_ids) == len(attn_mask) == len(loss_mask) == chunk_length\n",
    "            yield token_ids, attn_mask, loss_mask\n",
    "            mask_index = 1\n",
    "            token_ids, attn_mask, loss_mask = start_tokens.copy(), [1 for _ in range(len(start_tokens))], [0 for _ in range(len(start_tokens))]\n",
    "        else:\n",
    "            token_ids += start_tokens\n",
    "            attn_mask += [mask_index for _ in range(len(start_tokens))]\n",
    "            loss_mask += [0 for _ in range(len(start_tokens))]\n",
    "\n",
    "        msg_index, max_msg_index = 0, -1\n",
    "        while msg_index < len(dial_encoded):\n",
    "            src, msg = dial_encoded[msg_index]\n",
    "            append_length = min(chunk_length - len(token_ids), len(msg))\n",
    "            token_ids += msg[:append_length]\n",
    "            attn_mask += [mask_index for _ in range(append_length)]\n",
    "            loss_mask += [0 for _ in range(append_length)] if src == 'User' or msg_index <= max_msg_index else [1 for _ in range(append_length)]\n",
    "            max_msg_index = max(msg_index, max_msg_index)\n",
    "            if len(token_ids) == chunk_length:\n",
    "                assert len(token_ids) == len(attn_mask) == len(loss_mask) == chunk_length\n",
    "                yield token_ids, attn_mask, loss_mask\n",
    "                mask_index = 1\n",
    "                token_ids, attn_mask, loss_mask = [], [], []\n",
    "                msg_index -= min(overlap_count, msg_index)\n",
    "            else:\n",
    "                msg_index += 1\n",
    "\n",
    "    if len(token_ids) > len(start_tokens):\n",
    "        pad_length = chunk_length - len(token_ids)\n",
    "        token_ids += [0 for _ in range(pad_length)]\n",
    "        attn_mask += [chunk_length + 1 for _ in range(pad_length)]\n",
    "        loss_mask += [0 for _ in range(pad_length)]\n",
    "        assert len(token_ids) == len(attn_mask) == len(loss_mask) == chunk_length\n",
    "        yield token_ids, attn_mask, loss_mask\n",
    "\n",
    "    print(f'Skipped {skip_dialogue_count}/{len(dialogues)} dialogues.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:24:46.356837481Z",
     "start_time": "2023-11-02T06:24:46.346351152Z"
    }
   },
   "id": "4d4cdc0410da09e7"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def write_out_dataset(file, entries):\n",
    "    writer = DatasetWriter(file, {'token_ids': np.uint16, 'attn_mask': np.uint16, 'loss_mask': np.uint16})\n",
    "    for (token_ids, attn_mask, loss_mask) in tqdm(entries):\n",
    "        writer.add_entry(token_ids=np.array(token_ids, dtype=np.uint16),\n",
    "                         attn_mask=np.array(attn_mask, dtype=np.uint16),\n",
    "                         loss_mask=np.array(loss_mask, dtype=np.uint16))\n",
    "    writer.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:24:46.369425853Z",
     "start_time": "2023-11-02T06:24:46.355754804Z"
    }
   },
   "id": "5a2936bf78b4d29f"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "dialogues_to_chunks_1024 = partial(dialogues_to_chunks, chunk_length=1024, max_message_length=450, overlap_count=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:24:46.379036705Z",
     "start_time": "2023-11-02T06:24:46.369626337Z"
    }
   },
   "id": "599634ebe9529eba"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def alpaca_to_dialogue(alpaca_sample):\n",
    "    return [('User', alpaca_sample['instruction'] + (f'\\n{alpaca_sample[\"input\"]}' if alpaca_sample['input'] != '' else '')),\n",
    "            ('Assistant', alpaca_sample['output'])]\n",
    "\n",
    "\n",
    "alpaca_diags = [alpaca_to_dialogue(d) for d in alpaca_gpt['train']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:24:47.113869480Z",
     "start_time": "2023-11-02T06:24:46.379239568Z"
    }
   },
   "id": "f7f548285266d4c4"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/52002 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "862aa0b50c8940e69d07a5f7fca83713"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 2888/52002 dialogues.\n"
     ]
    }
   ],
   "source": [
    "alpaca_chunks = [x for x in dialogues_to_chunks_1024(alpaca_diags)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:24:57.528619992Z",
     "start_time": "2023-11-02T06:24:51.997016035Z"
    }
   },
   "id": "b8d9c00c339a9ade"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/9956 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fbf124d6d279409bb5b8bf9d8009e9da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "write_out_dataset('datasets/sft/alpaca_gpt4.bin', alpaca_chunks)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:24:58.061434214Z",
     "start_time": "2023-11-02T06:24:57.529320614Z"
    }
   },
   "id": "47f88fc2b7560672"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "airoboros_diags = [[('User', d['instruction']), ('Assistant', d['response'])] for d in airoboros['train'] if not 'contextual' in d['category']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:24:58.815746726Z",
     "start_time": "2023-11-02T06:24:58.092036949Z"
    }
   },
   "id": "a07e2445bed5ce56"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/40331 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3f285eb8d6e4d38a361145797d320f3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 11984/40331 dialogues.\n"
     ]
    }
   ],
   "source": [
    "airoboros_chunks = [x for x in dialogues_to_chunks_1024(airoboros_diags)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:25:07.060230986Z",
     "start_time": "2023-11-02T06:24:58.818404065Z"
    }
   },
   "id": "eeb552c069dfef66"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/7447 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a75cc7718c546d4b439a207d6bbc321"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "write_out_dataset('datasets/sft/airoboros_2.2.1.bin', airoboros_chunks)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:25:07.500917449Z",
     "start_time": "2023-11-02T06:25:07.060328990Z"
    }
   },
   "id": "1965469a519fc50b"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "wizardlm_diags = [[('User' if msg['from'] == 'human' else 'Assistant', msg['value']) for msg in diag] for diag in wizardlm['train']['conversations']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:25:08.975375239Z",
     "start_time": "2023-11-02T06:25:07.500826011Z"
    }
   },
   "id": "ac6cbd4ad2be241d"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/143000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3302584dab1f4c4187daf72bf75a6d82"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 61171/143000 dialogues.\n"
     ]
    }
   ],
   "source": [
    "wizardlm_chunks = [x for x in dialogues_to_chunks_1024(wizardlm_diags)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:25:46.091060488Z",
     "start_time": "2023-11-02T06:25:08.978603504Z"
    }
   },
   "id": "32fdbfc8a41e5a64"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/35655 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e7362536b6d44ebb22aab811b540d31"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "write_out_dataset('datasets/sft/wizardlm_evol_2.bin', wizardlm_chunks)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:25:48.010575531Z",
     "start_time": "2023-11-02T06:25:46.091827948Z"
    }
   },
   "id": "fdedb28c9fe67ceb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "56ea6d05afd4304b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f460024f9b61f5b7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

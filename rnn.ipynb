{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-08-12T12:00:15.310874Z",
     "end_time": "2023-08-12T12:00:15.317010Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import tokenizers\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "with open('corpus/tiny_shakespeare.txt', 'r') as file:\n",
    "    raw_text = file.read()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-12T10:28:57.279212Z",
     "end_time": "2023-08-12T10:28:57.284810Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "tokenizer = tokenizers.WordTokenizer(raw_text, vocab_size=3000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-12T10:28:57.511813Z",
     "end_time": "2023-08-12T10:28:57.635002Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(tokenizer.get_vocab_mapping())\n",
    "EMB_SIZE = 128\n",
    "HIDDEN_SIZE = 128\n",
    "CTX_LEN = 32"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-12T10:28:57.655729Z",
     "end_time": "2023-08-12T10:28:57.659685Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "encoded = tokenizer.encode(raw_text)\n",
    "batched = [encoded[i:i + CTX_LEN] for i in range(len(encoded) - CTX_LEN)]\n",
    "batched = torch.tensor(batched)\n",
    "sub_batched = batched[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-12T10:28:57.865128Z",
     "end_time": "2023-08-12T10:29:00.005564Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "embedding = torch.randn((VOCAB_SIZE, EMB_SIZE)) * math.sqrt(2 / VOCAB_SIZE)\n",
    "hiddenWx = torch.randn((EMB_SIZE, HIDDEN_SIZE)) * math.sqrt(2 / EMB_SIZE)\n",
    "hiddenWh = torch.randn((EMB_SIZE, HIDDEN_SIZE)) * math.sqrt(2 / EMB_SIZE)\n",
    "hiddenB = torch.zeros((HIDDEN_SIZE,))\n",
    "outputW = torch.randn((HIDDEN_SIZE, VOCAB_SIZE)) * math.sqrt(2 / HIDDEN_SIZE)\n",
    "outputB = torch.zeros((VOCAB_SIZE,))\n",
    "params = [embedding, hiddenWx, hiddenWh, hiddenB, outputW, outputB]\n",
    "for p in params:\n",
    "    p.requires_grad = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-12T10:31:16.196340Z",
     "end_time": "2023-08-12T10:31:16.221415Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "804153"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-12T10:31:17.843024Z",
     "end_time": "2023-08-12T10:31:17.849710Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def rnn_forward(x, state):\n",
    "    emb = F.one_hot(x, num_classes=VOCAB_SIZE).float() @ embedding\n",
    "    new_state = F.tanh(emb @ hiddenWx + state @ hiddenWh + hiddenB)\n",
    "    logits = new_state @ outputW + outputB\n",
    "    return logits, new_state"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-12T10:31:18.313280Z",
     "end_time": "2023-08-12T10:31:18.317651Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def predict(prompt: str, max_new_tokens: int):\n",
    "    ids = tokenizer.encode(prompt)\n",
    "    state, logits = torch.zeros((1, HIDDEN_SIZE)), None\n",
    "    for i in ids:\n",
    "        logits, state = rnn_forward(torch.tensor([i]), state)\n",
    "    ids.append(torch.argmax(logits).item())\n",
    "    for i in range(max_new_tokens):\n",
    "        logits, state = rnn_forward(torch.tensor(ids[-1]), state)\n",
    "        ids.append(torch.argmax(logits).item())\n",
    "    # print(ids)\n",
    "    return tokenizer.decode(ids)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-12T10:31:19.061387Z",
     "end_time": "2023-08-12T10:31:19.066136Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lordthunderdrewoursremainsHastingstakesmissjoysslayhornroguefewforcerunseestBelieveMeratherforknavescontractforswornearsthreadstamptriumphantbeholdingloseBolingbrokestarsfightconsentrt\n"
     ]
    }
   ],
   "source": [
    "print(predict('lord', 32))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-12T10:31:19.604893Z",
     "end_time": "2023-08-12T10:31:19.620040Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Step: 0, Loss: 3.15\n",
      "Epoch: 0 Step: 10240, Loss: 3.11\n",
      "Epoch: 0 Step: 20480, Loss: 3.11\n",
      "Epoch: 0 Step: 30720, Loss: 3.07\n",
      "Epoch: 0 Step: 40960, Loss: 3.10\n",
      "Epoch: 0 Step: 51200, Loss: 3.12\n",
      "Epoch: 0 Step: 61440, Loss: 3.07\n",
      "Epoch: 0 Step: 71680, Loss: 3.02\n",
      "Epoch: 0 Step: 81920, Loss: 3.03\n",
      "Epoch: 0 Step: 92160, Loss: 3.02\n",
      "Epoch: 0 Step: 102400, Loss: 3.02\n",
      "Epoch: 0 Step: 112640, Loss: 3.04\n",
      "Epoch: 0 Step: 122880, Loss: 3.10\n",
      "Epoch: 0 Step: 133120, Loss: 3.08\n",
      "Epoch: 0 Step: 143360, Loss: 3.08\n",
      "Epoch: 0 Step: 153600, Loss: 3.07\n",
      "Epoch: 0 Step: 163840, Loss: 3.07\n",
      "Epoch: 0 Step: 174080, Loss: 3.08\n",
      "Epoch: 0 Step: 184320, Loss: 3.07\n",
      "Epoch: 0 Step: 194560, Loss: 3.01\n",
      "Epoch: 0 Step: 204800, Loss: 3.06\n",
      "Epoch: 0 Step: 215040, Loss: 3.11\n",
      "Epoch: 0 Step: 225280, Loss: 3.06\n",
      "Epoch: 0 Step: 235520, Loss: 3.03\n",
      "Epoch: 0 Step: 245760, Loss: 3.03\n",
      "Epoch: 0 Step: 256000, Loss: 3.05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [47]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     17\u001B[0m     nll\u001B[38;5;241m.\u001B[39mbackward(retain_graph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m params:\n\u001B[0;32m---> 19\u001B[0m         p\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m LR \u001B[38;5;241m*\u001B[39m p\u001B[38;5;241m.\u001B[39mgrad\n\u001B[1;32m     20\u001B[0m     accu_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m nll\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Step: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mb_i\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00maccu_loss \u001B[38;5;241m/\u001B[39m (CTX_LEN \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m)\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 10240\n",
    "EPOCHS = 1\n",
    "LR = 0.01\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for b_i in range(0, len(batched), BATCH_SIZE):\n",
    "        mini_batch = batched[b_i:b_i + BATCH_SIZE]\n",
    "        state = torch.zeros((len(mini_batch), HIDDEN_SIZE))\n",
    "        accu_loss = 0.0\n",
    "        for i in range(CTX_LEN - 1):\n",
    "            logits, state = rnn_forward(mini_batch[:, i], state.clone().detach().requires_grad_(True))\n",
    "            logits = torch.softmax(logits, dim=1)\n",
    "            y = mini_batch[:, i + 1]\n",
    "            nll = -torch.log(logits[torch.arange(len(logits)), y]).mean()\n",
    "            for p in params:\n",
    "                p.grad = None\n",
    "            nll.backward(retain_graph=False)\n",
    "            for p in params:\n",
    "                p.data -= LR * p.grad\n",
    "            accu_loss += nll.item()\n",
    "        print(f'Epoch: {epoch} Step: {b_i}, Loss: {accu_loss / (CTX_LEN - 1):.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-12T10:35:53.818279Z",
     "end_time": "2023-08-12T11:18:00.667806Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "'First <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> '"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('First', 32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-12T12:02:50.329300Z",
     "end_time": "2023-08-12T12:02:50.346517Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text[:100]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-12T10:35:47.936238Z",
     "end_time": "2023-08-12T10:35:47.940055Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

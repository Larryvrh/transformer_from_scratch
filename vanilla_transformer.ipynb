{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from tokenizers import WordTokenizer, CharTokenizer\n",
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "import tqdm.notebook as tqdm\n",
    "import time\n",
    "import bisect\n",
    "import random\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e76bcba3a904db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./corpus/TinyStoriesV2-GPT4-valid.txt', 'r') as file:\n",
    "    lines = [l.strip() for l in file.read().split('<|endoftext|>')[:-1]]\n",
    "    raw_text = '\\n'.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb151752ec125fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network definition\n",
    "C_SEQ_LEN = 512\n",
    "C_VOCAB_SIZE = 4096\n",
    "C_HIDDEN_SIZE = 384\n",
    "C_NUM_HEADS = 6\n",
    "C_NUM_LAYERS = 6\n",
    "\n",
    "C_DEVICE = torch.device('cpu')\n",
    "C_DTYPE = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33702a8e6613f742",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WordTokenizer(raw_text, vocab_size=C_VOCAB_SIZE, reserved_vocab=['<s>', '</s>', '<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf7fc22d44a2d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.eval_vocab_coverage(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6236ac3649c35eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids, position_ids, attn_mask, loss_mask = [[]], [[]], [[]], None\n",
    "mask_index = 1\n",
    "for l in tqdm.tqdm(lines):\n",
    "    cursor = 0\n",
    "    sample_token_ids = tokenizer.encode('<s>' + l + '</s>')\n",
    "    sample_position_ids = list(range(len(sample_token_ids)))\n",
    "    while cursor < len(sample_token_ids):\n",
    "        length = min(C_SEQ_LEN - len(token_ids[-1]), len(sample_token_ids) - cursor)\n",
    "        token_ids[-1] += sample_token_ids[cursor:cursor + length]\n",
    "        position_ids[-1] += sample_position_ids[cursor:cursor + length]\n",
    "        attn_mask[-1] += [mask_index] * length\n",
    "        cursor += length\n",
    "        mask_index += 1\n",
    "        if len(token_ids[-1]) == C_SEQ_LEN:\n",
    "            token_ids.append([])\n",
    "            position_ids.append([])\n",
    "            attn_mask.append([])\n",
    "            mask_index = 1\n",
    "token_ids = torch.tensor(token_ids[:-1])\n",
    "position_ids = torch.tensor(position_ids[:-1])\n",
    "attn_mask = torch.tensor(attn_mask[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb60031d199ad9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_seq = torch.tensor([tokenizer.encode(raw_text[:10000])[:128 * 8]]).view((-1, 128))\n",
    "debug_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d4a7cb7e49d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_attn_mask(custom_attn_mask: torch.Tensor):\n",
    "    B, T = custom_attn_mask.shape\n",
    "    mask = custom_attn_mask.unsqueeze(1).repeat((1, T, 1))\n",
    "    seq_index_mask = (mask == custom_attn_mask[:, torch.arange(T)].view(B, T, 1))\n",
    "    return seq_index_mask & (torch.tril(mask) > 0)\n",
    "\n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, num_heads: int, hidden_size: int, dtype: torch.dtype = torch.float32):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dtype = dtype\n",
    "        self.q_proj = nn.Linear(hidden_size, hidden_size // num_heads, dtype=dtype)\n",
    "        self.k_proj = nn.Linear(hidden_size, hidden_size // num_heads, dtype=dtype)\n",
    "        self.v_proj = nn.Linear(hidden_size, hidden_size // num_heads, dtype=dtype)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, attn_mask: Optional[torch.Tensor],\n",
    "                kv_cache: Optional[List[torch.Tensor]]) -> Tuple[torch.Tensor, List[torch.Tensor]]:\n",
    "        B, T, C = x.shape\n",
    "\n",
    "        mask_zero = torch.tensor(0, dtype=self.dtype)\n",
    "        mask_val = torch.tensor(torch.finfo(self.dtype).min / 2, dtype=self.dtype)\n",
    "        if kv_cache is None and attn_mask is not None:\n",
    "            causal_mask = torch.where(expand_attn_mask(attn_mask), mask_zero, mask_val)\n",
    "        elif kv_cache is None:\n",
    "            causal_mask = torch.where(expand_attn_mask(torch.ones(x.shape[:2])), mask_zero, mask_val)\n",
    "        else:\n",
    "            causal_mask = torch.zeros((B, T, T), dtype=self.dtype)\n",
    "\n",
    "        q = self.q_proj(x)\n",
    "        k = self.k_proj(x)\n",
    "        v = self.v_proj(x)\n",
    "        if kv_cache is not None:\n",
    "            k = torch.concat([kv_cache[0], k], dim=1)\n",
    "            v = torch.concat([kv_cache[1], v], dim=1)\n",
    "\n",
    "        attn_score = (q @ k.permute(0, 2, 1) / (self.hidden_size ** 0.5)) + causal_mask.to(q.device)\n",
    "\n",
    "        return torch.softmax(attn_score, dim=2) @ v, [k, v]\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads: int, hidden_size: int, dtype: torch.dtype = torch.float32):\n",
    "        super().__init__()\n",
    "        self.attn_heads = nn.ModuleList([AttentionHead(num_heads, hidden_size, dtype) for _ in range(num_heads)])\n",
    "        self.o_proj = nn.Linear(hidden_size, hidden_size, dtype=dtype)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, attn_mask: Optional[torch.Tensor],\n",
    "                kv_cache: Optional[List[torch.Tensor]]) -> Tuple[torch.Tensor, List[List[torch.Tensor]]]:\n",
    "        head_outputs = [head(x, attn_mask, kv_cache[idx] if kv_cache is not None else None) for idx, head in\n",
    "                        enumerate(self.attn_heads)]\n",
    "        return self.o_proj(torch.concat([o[0] for o in head_outputs], dim=2)), [o[1] for o in head_outputs]\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, num_heads: int, hidden_size: int, dtype: torch.dtype = torch.float32):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(num_heads, hidden_size, dtype)\n",
    "        self.up_proj = nn.Linear(hidden_size, hidden_size * 4, dtype=dtype)\n",
    "        self.down_proj = nn.Linear(hidden_size * 4, hidden_size, dtype=dtype)\n",
    "        self.ln_mha = nn.LayerNorm(hidden_size, dtype=dtype)\n",
    "        self.ln_ffn = nn.LayerNorm(hidden_size, dtype=dtype)\n",
    "        self.act = nn.GELU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, attn_mask: Optional[torch.Tensor],\n",
    "                kv_cache: Optional[List[torch.Tensor]]) -> Tuple[torch.Tensor, List[List[torch.Tensor]]]:\n",
    "        mha_output, new_kv_cache = self.mha(self.ln_mha(x), attn_mask, kv_cache)\n",
    "        mha_output = x + mha_output\n",
    "        ffn_output = self.down_proj(self.act(self.up_proj(self.ln_ffn(mha_output))))\n",
    "        return mha_output + ffn_output, new_kv_cache\n",
    "\n",
    "\n",
    "class ToyTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size: int, num_layers: int, num_heads: int, hidden_size: int, seq_len: int,\n",
    "                 dtype: torch.dtype = torch.float32):\n",
    "        super().__init__()\n",
    "        self.sem_embed = nn.Embedding(vocab_size, hidden_size, dtype=dtype)\n",
    "        self.pos_embed = nn.Embedding(seq_len, hidden_size, dtype=dtype)\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(num_heads, hidden_size, dtype) for _ in range(num_layers)])\n",
    "        self.lm_head = nn.Linear(hidden_size, vocab_size, dtype=dtype)\n",
    "\n",
    "    def forward(self, seq: torch.Tensor,\n",
    "                position_ids: Optional[torch.Tensor] = None,\n",
    "                attn_mask: Optional[torch.Tensor] = None,\n",
    "                kv_cache: Optional[List[torch.Tensor]] = None) -> Tuple[torch.Tensor, List[List[List[torch.Tensor]]]]:\n",
    "\n",
    "        if position_ids is None:\n",
    "            seq_len = seq.shape[1]\n",
    "            pos_embed = self.pos_embed(torch.arange(0, seq_len, 1).to(self.device))\n",
    "        else:\n",
    "            pos_embed = self.pos_embed(position_ids)\n",
    "\n",
    "        hidden = self.sem_embed(seq) + pos_embed\n",
    "        new_kv_cache = []\n",
    "        for idx, decoder in enumerate(self.decoder_layers):\n",
    "            hidden, layer_kv_cache = decoder(hidden, attn_mask, kv_cache[idx] if kv_cache is not None else None)\n",
    "            new_kv_cache.append(layer_kv_cache)\n",
    "\n",
    "        return self.lm_head(hidden), new_kv_cache\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d124589733f9ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ToyTransformer(C_VOCAB_SIZE, C_NUM_LAYERS, C_NUM_HEADS, C_HIDDEN_SIZE, C_SEQ_LEN)\n",
    "model = model.to(C_DEVICE)\n",
    "print('Total parameters:', sum([t.numel() for t in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f906aed5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-3, total_steps=2000, final_div_factor=1e2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6704e7b3092a4c0c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaba00d2720d53e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "C_BATCH_SIZE = 32\n",
    "for epoch_num in range(1):\n",
    "    for batch_i in tqdm.tqdm(list(range(0, len(token_ids), C_BATCH_SIZE))):\n",
    "        step_start_time = time.time()\n",
    "\n",
    "        inputs = token_ids[batch_i:batch_i + C_BATCH_SIZE, :-1]\n",
    "        labels = token_ids[batch_i:batch_i + C_BATCH_SIZE, 1:]\n",
    "        masks = attn_mask[batch_i:batch_i + C_BATCH_SIZE, :-1]\n",
    "        # masks = train_mask[batch_i:batch_i + C_BATCH_SIZE, 1:].to(model.device, C_DTYPE)\n",
    "\n",
    "        logits, _ = model.forward(inputs.to(model.device), attn_mask=masks)\n",
    "        probs = torch.softmax(logits, dim=2)  # BSZ * SEQ * VOCAB\n",
    "        probs_flat = probs.view(-1, C_VOCAB_SIZE)\n",
    "        #  * masks.reshape(-1)\n",
    "        loss = (-torch.log(probs_flat[torch.arange(probs_flat.shape[0]), labels.reshape(-1)])).mean()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        step_time_cost = time.time() - step_start_time\n",
    "        throughput = round((C_BATCH_SIZE * C_SEQ_LEN) / step_time_cost / 1000, 2)\n",
    "        print(\n",
    "            f'Epoch {epoch_num} Step {batch_i // C_BATCH_SIZE + 1} - Loss: {loss.item():.3f} LR: {scheduler.get_last_lr()[0]:.3} '\n",
    "            f'Throughput: {throughput} kts')\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e800403549c98d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(tokenizer, prompt, temperature, top_p, rep_penalty, max_new_tokens=20, total_tokens=None):\n",
    "    feed_tokens = tokenizer.encode(prompt)\n",
    "    all_tokens = feed_tokens.copy()\n",
    "    if total_tokens is not None:\n",
    "        max_new_tokens = max(0, total_tokens - len(feed_tokens))\n",
    "\n",
    "    kv_cache = None\n",
    "    for _ in range(max_new_tokens):\n",
    "        position_ids = None if kv_cache is None else torch.tensor([[len(all_tokens) - 1]]).to(C_DEVICE)\n",
    "        logits, kv_cache = model.forward(torch.tensor([feed_tokens]).to(C_DEVICE),\n",
    "                                         position_ids=position_ids,\n",
    "                                         kv_cache=kv_cache)\n",
    "        logits = logits[0][-1].cpu()\n",
    "\n",
    "        # apply repetition penalty\n",
    "        logits_rep = torch.gather(logits, 0, torch.tensor(all_tokens))\n",
    "        logits_rep = torch.where(logits_rep < 0, logits_rep * rep_penalty, logits_rep / rep_penalty)\n",
    "        logits.scatter_(0, torch.tensor(all_tokens), logits_rep)\n",
    "\n",
    "        # apply temperature\n",
    "        logits /= max(temperature, 1e-6)\n",
    "\n",
    "        probs = torch.softmax(logits, dim=0)\n",
    "\n",
    "        # apply top-p\n",
    "        ordered_probs, ordered_indices = torch.sort(probs, descending=True)\n",
    "        cum_probs = torch.cumsum(ordered_probs, dim=0).tolist()\n",
    "        top_p_index = bisect.bisect_right(cum_probs, top_p) + 1\n",
    "        ordered_probs, ordered_indices = ordered_probs[:top_p_index], ordered_indices[:top_p_index]\n",
    "        sampled_index = ordered_indices[torch.multinomial(ordered_probs, num_samples=1).item()].item()\n",
    "\n",
    "        all_tokens.append(sampled_index)\n",
    "        feed_tokens = [sampled_index]\n",
    "    # print(tokens)\n",
    "    return tokenizer.decode(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc924753b5acfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = time.time()\n",
    "print(generate(tokenizer, 'Mommy', 1.0, 0.01, 1.0, total_tokens=256))\n",
    "print(time.time() - a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dfb4a3c8dcbb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(debug_seq[-1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191841b1a87d1069",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(torch.finfo(torch.bfloat16).min / 2, dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3a25faa06d3e1a9c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e6b62aa4b37ffe30"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

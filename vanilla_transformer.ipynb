{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2023-10-11T03:51:12.337133113Z",
     "start_time": "2023-10-11T03:51:11.774278456Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from tokenizers import WordTokenizer, CharTokenizer\n",
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "import tqdm.notebook as tqdm\n",
    "import time\n",
    "import bisect\n",
    "import random\n",
    "from typing import *\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40e76bcba3a904db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T03:51:18.114974863Z",
     "start_time": "2023-10-11T03:51:12.337916212Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./corpus/TinyStoriesV2-GPT4-train.txt', 'r') as file:\n",
    "    raw_text = file.read()\n",
    "    lines = [l.strip() for l in raw_text.split('<|endoftext|>')[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fb151752ec125fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T03:51:18.115146792Z",
     "start_time": "2023-10-11T03:51:18.112306705Z"
    }
   },
   "outputs": [],
   "source": [
    "# Network definition\n",
    "C_SEQ_LEN = 512\n",
    "C_VOCAB_SIZE = 4096\n",
    "C_HIDDEN_SIZE = 512\n",
    "C_NUM_HEADS = 8\n",
    "C_NUM_LAYERS = 8\n",
    "\n",
    "C_DEVICE = torch.device('cuda')\n",
    "C_DTYPE = torch.bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "2226845268"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T03:51:18.165023511Z",
     "start_time": "2023-10-11T03:51:18.113945789Z"
    }
   },
   "id": "111829d7be3d3949"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33702a8e6613f742",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T03:51:27.604574661Z",
     "start_time": "2023-10-11T03:51:18.165457565Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = WordTokenizer(raw_text[:100000000], vocab_size=C_VOCAB_SIZE, reserved_vocab=['<s>', '</s>', '<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdf7fc22d44a2d77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T03:51:38.638387721Z",
     "start_time": "2023-10-11T03:51:27.756210759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.996570014053978"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eval_vocab_coverage(raw_text[100000000:200000000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T03:51:38.723648927Z",
     "start_time": "2023-10-11T03:51:38.712489884Z"
    }
   },
   "id": "da1334b7c7584ee"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6236ac3649c35eb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T03:51:38.736007627Z",
     "start_time": "2023-10-11T03:51:38.714885040Z"
    }
   },
   "outputs": [],
   "source": [
    "# token_ids, position_ids, attn_mask, loss_mask = [[]], [[]], [[]], None\n",
    "# mask_index = 1\n",
    "# for l in tqdm.tqdm(lines):\n",
    "#     cursor = 0\n",
    "#     sample_token_ids = tokenizer.encode('<s>' + l + '</s>')\n",
    "#     if len(sample_token_ids) > C_SEQ_LEN:\n",
    "#         continue\n",
    "#     sample_position_ids = list(range(len(sample_token_ids)))\n",
    "#     while cursor < len(sample_token_ids):\n",
    "#         length = min(C_SEQ_LEN - len(token_ids[-1]), len(sample_token_ids) - cursor)\n",
    "#         token_ids[-1] += sample_token_ids[cursor:cursor + length]\n",
    "#         position_ids[-1] += sample_position_ids[cursor:cursor + length]\n",
    "#         attn_mask[-1] += [mask_index] * length\n",
    "#         cursor += length\n",
    "#         mask_index += 1\n",
    "#         if len(token_ids[-1]) == C_SEQ_LEN:\n",
    "#             token_ids.append([])\n",
    "#             position_ids.append([])\n",
    "#             attn_mask.append([])\n",
    "#             mask_index = 1\n",
    "# token_ids = torch.tensor(token_ids[:-1])\n",
    "# position_ids = torch.tensor(position_ids[:-1])\n",
    "# attn_mask = torch.tensor(attn_mask[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# with open('tiny_stories_tokenized.pt', 'wb') as file:\n",
    "#     torch.save([token_ids, position_ids, attn_mask], file)\n",
    "with open('tiny_stories_tokenized.pt', 'rb') as file:\n",
    "    token_ids, position_ids, attn_mask = torch.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T03:51:46.152520673Z",
     "start_time": "2023-10-11T03:51:38.733675254Z"
    }
   },
   "id": "799b78921dbff1ec"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb60031d199ad9a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T03:51:46.194756500Z",
     "start_time": "2023-10-11T03:51:46.194385678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([8, 128])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_seq = torch.tensor([tokenizer.encode(raw_text[:10000])[:128 * 8]]).view((-1, 128))\n",
    "debug_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "34d4a7cb7e49d5f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T04:01:57.850613827Z",
     "start_time": "2023-10-11T04:01:57.808962469Z"
    }
   },
   "outputs": [],
   "source": [
    "def expand_attn_mask(custom_attn_mask: torch.Tensor):\n",
    "    B, T = custom_attn_mask.shape\n",
    "    mask = custom_attn_mask.unsqueeze(1).repeat((1, T, 1))\n",
    "    seq_index_mask = (mask == custom_attn_mask[:, torch.arange(T)].view(B, T, 1))\n",
    "    return seq_index_mask & (torch.tril(mask) > 0)\n",
    "\n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, num_heads: int, hidden_size: int, dtype: torch.dtype = torch.float32):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dtype = dtype\n",
    "        self.q_proj = nn.Linear(hidden_size, hidden_size // num_heads, dtype=dtype)\n",
    "        self.k_proj = nn.Linear(hidden_size, hidden_size // num_heads, dtype=dtype)\n",
    "        self.v_proj = nn.Linear(hidden_size, hidden_size // num_heads, dtype=dtype)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, attn_mask: Optional[torch.Tensor],\n",
    "                kv_cache: Optional[List[torch.Tensor]]) -> Tuple[torch.Tensor, List[torch.Tensor]]:\n",
    "        # flash attn isn't currently supported due to custom attn mask\n",
    "        flash_attn_enabled = (self.dtype == torch.float16 or self.dtype == torch.bfloat16) and not globals().get('disable_flash_attn', False)\n",
    "\n",
    "        B, T, C = x.shape\n",
    "\n",
    "        mask_zero = torch.tensor(0, dtype=self.dtype)\n",
    "        mask_val = torch.tensor(torch.finfo(self.dtype).min / 2, dtype=self.dtype)\n",
    "        if kv_cache is None and attn_mask is not None:\n",
    "            causal_mask = expand_attn_mask(attn_mask)\n",
    "        elif kv_cache is None:\n",
    "            causal_mask = expand_attn_mask(torch.ones(x.shape[:2]))\n",
    "        else:\n",
    "            causal_mask = torch.ones((B, T, T), dtype=torch.bool)\n",
    "        if not flash_attn_enabled:\n",
    "            causal_mask = torch.where(causal_mask, mask_zero, mask_val)\n",
    "\n",
    "        q = self.q_proj(x)\n",
    "        k = self.k_proj(x)\n",
    "        v = self.v_proj(x)\n",
    "        if kv_cache is not None:\n",
    "            k = torch.concat([kv_cache[0], k], dim=1)\n",
    "            v = torch.concat([kv_cache[1], v], dim=1)\n",
    "\n",
    "        if flash_attn_enabled:\n",
    "            # noinspection PyUnresolvedReferences\n",
    "            with torch.backends.cuda.sdp_kernel(enable_flash=False, enable_math=True, enable_mem_efficient=True):\n",
    "                attn_result = nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=causal_mask.to(q.device))\n",
    "        else:\n",
    "            attn_score = (q @ k.permute(0, 2, 1) / (self.hidden_size ** 0.5)) + causal_mask.to(q.device)\n",
    "            attn_result = torch.softmax(attn_score, dim=2) @ v\n",
    "\n",
    "        return attn_result, [k, v]\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads: int, hidden_size: int, dtype: torch.dtype = torch.float32):\n",
    "        super().__init__()\n",
    "        self.attn_heads = nn.ModuleList([AttentionHead(num_heads, hidden_size, dtype) for _ in range(num_heads)])\n",
    "        self.o_proj = nn.Linear(hidden_size, hidden_size, dtype=dtype)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, attn_mask: Optional[torch.Tensor],\n",
    "                kv_cache: Optional[List[torch.Tensor]]) -> Tuple[torch.Tensor, List[List[torch.Tensor]]]:\n",
    "        head_outputs = [head(x, attn_mask, kv_cache[idx] if kv_cache is not None else None) for idx, head in\n",
    "                        enumerate(self.attn_heads)]\n",
    "        return self.o_proj(torch.concat([o[0] for o in head_outputs], dim=2)), [o[1] for o in head_outputs]\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, num_heads: int, hidden_size: int, dtype: torch.dtype = torch.float32):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(num_heads, hidden_size, dtype)\n",
    "        self.up_proj = nn.Linear(hidden_size, hidden_size * 4, dtype=dtype)\n",
    "        self.down_proj = nn.Linear(hidden_size * 4, hidden_size, dtype=dtype)\n",
    "        self.ln_mha = nn.LayerNorm(hidden_size, dtype=dtype)\n",
    "        self.ln_ffn = nn.LayerNorm(hidden_size, dtype=dtype)\n",
    "        self.act = nn.GELU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, attn_mask: Optional[torch.Tensor],\n",
    "                kv_cache: Optional[List[torch.Tensor]]) -> Tuple[torch.Tensor, List[List[torch.Tensor]]]:\n",
    "        mha_output, new_kv_cache = self.mha(self.ln_mha(x), attn_mask, kv_cache)\n",
    "        mha_output = x + mha_output\n",
    "        ffn_output = self.down_proj(self.act(self.up_proj(self.ln_ffn(mha_output))))\n",
    "        return mha_output + ffn_output, new_kv_cache\n",
    "\n",
    "\n",
    "class ToyTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size: int, num_layers: int, num_heads: int, hidden_size: int, seq_len: int,\n",
    "                 dtype: torch.dtype = torch.float32):\n",
    "        super().__init__()\n",
    "        self.sem_embed = nn.Embedding(vocab_size, hidden_size, dtype=dtype)\n",
    "        self.pos_embed = nn.Embedding(seq_len, hidden_size, dtype=dtype)\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(num_heads, hidden_size, dtype) for _ in range(num_layers)])\n",
    "        self.lm_head = nn.Linear(hidden_size, vocab_size, dtype=dtype)\n",
    "\n",
    "    def forward(self, seq: torch.Tensor,\n",
    "                position_ids: Optional[torch.Tensor] = None,\n",
    "                attn_mask: Optional[torch.Tensor] = None,\n",
    "                kv_cache: Optional[List[torch.Tensor]] = None) -> Tuple[torch.Tensor, List[List[List[torch.Tensor]]]]:\n",
    "\n",
    "        if position_ids is None:\n",
    "            seq_len = seq.shape[1]\n",
    "            pos_embed = self.pos_embed(torch.arange(0, seq_len, 1).to(self.device))\n",
    "        else:\n",
    "            pos_embed = self.pos_embed(position_ids)\n",
    "\n",
    "        hidden = self.sem_embed(seq) + pos_embed\n",
    "        new_kv_cache = []\n",
    "        for idx, decoder in enumerate(self.decoder_layers):\n",
    "            hidden, layer_kv_cache = decoder(hidden, attn_mask, kv_cache[idx] if kv_cache is not None else None)\n",
    "            new_kv_cache.append(layer_kv_cache)\n",
    "\n",
    "        return self.lm_head(hidden), new_kv_cache\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d124589733f9ed1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T04:01:58.269083084Z",
     "start_time": "2023-10-11T04:01:58.134657259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 29679616\n"
     ]
    }
   ],
   "source": [
    "model = ToyTransformer(C_VOCAB_SIZE, C_NUM_LAYERS, C_NUM_HEADS, C_HIDDEN_SIZE, C_SEQ_LEN, C_DTYPE)\n",
    "model = model.to(C_DEVICE)\n",
    "print('Total parameters:', sum([t.numel() for t in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "ToyTransformer(\n  (sem_embed): Embedding(4096, 512)\n  (pos_embed): Embedding(512, 512)\n  (decoder_layers): ModuleList(\n    (0-7): 8 x DecoderLayer(\n      (mha): MultiHeadAttention(\n        (attn_heads): ModuleList(\n          (0-7): 8 x AttentionHead(\n            (q_proj): Linear(in_features=512, out_features=64, bias=True)\n            (k_proj): Linear(in_features=512, out_features=64, bias=True)\n            (v_proj): Linear(in_features=512, out_features=64, bias=True)\n          )\n        )\n        (o_proj): Linear(in_features=512, out_features=512, bias=True)\n      )\n      (up_proj): Linear(in_features=512, out_features=2048, bias=True)\n      (down_proj): Linear(in_features=2048, out_features=512, bias=True)\n      (ln_mha): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (ln_ffn): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (act): GELU(approximate='none')\n    )\n  )\n  (lm_head): Linear(in_features=512, out_features=4096, bias=True)\n)"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T04:01:58.510687893Z",
     "start_time": "2023-10-11T04:01:58.505225730Z"
    }
   },
   "id": "f906aed5"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "C_BATCH_SIZE = 64"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T04:01:58.865416529Z",
     "start_time": "2023-10-11T04:01:58.861360555Z"
    }
   },
   "id": "a4c472b0aec53d7a"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-3, total_steps=len(token_ids) // C_BATCH_SIZE + 1, final_div_factor=1e2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T04:01:59.268265327Z",
     "start_time": "2023-10-11T04:01:59.265015794Z"
    }
   },
   "id": "6704e7b3092a4c0c"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./tiny_stories_0.8_epoch.pt'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T04:01:59.841293565Z",
     "start_time": "2023-10-11T04:01:59.776398851Z"
    }
   },
   "id": "7cb50733c6a6feaf"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T04:02:00.329633564Z",
     "start_time": "2023-10-11T04:02:00.259794557Z"
    }
   },
   "id": "dca6004e9b65892c"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eaba00d2720d53e6",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-10-11T04:02:05.021610800Z",
     "start_time": "2023-10-11T04:02:00.668864969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Epoch 0:   0%|          | 0/24243 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "01f10b6a0f2d4afeb817f947928b8c43"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[85], line 23\u001B[0m\n\u001B[1;32m     21\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     22\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m---> 23\u001B[0m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m step_time_cost \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m step_start_time\n\u001B[1;32m     26\u001B[0m throughput \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mround\u001B[39m((C_BATCH_SIZE \u001B[38;5;241m*\u001B[39m C_SEQ_LEN) \u001B[38;5;241m/\u001B[39m step_time_cost \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m1000\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:69\u001B[0m, in \u001B[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m instance\u001B[38;5;241m.\u001B[39m_step_count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     68\u001B[0m wrapped \u001B[38;5;241m=\u001B[39m func\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__get__\u001B[39m(instance, \u001B[38;5;28mcls\u001B[39m)\n\u001B[0;32m---> 69\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/optim/optimizer.py:280\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    276\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    277\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    278\u001B[0m                                \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbut got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 280\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    281\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    283\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/optim/optimizer.py:33\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     32\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m---> 33\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     35\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(prev_grad)\n",
      "File \u001B[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/optim/adamw.py:171\u001B[0m, in \u001B[0;36mAdamW.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    158\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    160\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[1;32m    161\u001B[0m         group,\n\u001B[1;32m    162\u001B[0m         params_with_grad,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    168\u001B[0m         state_steps,\n\u001B[1;32m    169\u001B[0m     )\n\u001B[0;32m--> 171\u001B[0m     \u001B[43madamw\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m        \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[43m        \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    184\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    185\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    186\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcapturable\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdifferentiable\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    188\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfused\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfused\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    189\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgrad_scale\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    190\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfound_inf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    191\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    193\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/optim/adamw.py:321\u001B[0m, in \u001B[0;36madamw\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    319\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adamw\n\u001B[0;32m--> 321\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    322\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    323\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    324\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    325\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    326\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    327\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    328\u001B[0m \u001B[43m    \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    329\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    330\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    331\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    332\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    333\u001B[0m \u001B[43m    \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    334\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    335\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapturable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    336\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdifferentiable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    337\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    338\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfound_inf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    339\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/optim/adamw.py:485\u001B[0m, in \u001B[0;36m_multi_tensor_adamw\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[1;32m    481\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m maximize:\n\u001B[1;32m    482\u001B[0m     device_grads \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39m_foreach_neg(\u001B[38;5;28mtuple\u001B[39m(device_grads))  \u001B[38;5;66;03m# type: ignore[assignment]\u001B[39;00m\n\u001B[0;32m--> 485\u001B[0m device_grads \u001B[38;5;241m=\u001B[39m [torch\u001B[38;5;241m.\u001B[39mview_as_real(x) \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mis_complex(x) \u001B[38;5;28;01melse\u001B[39;00m x \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m device_grads]\n\u001B[1;32m    486\u001B[0m device_exp_avgs \u001B[38;5;241m=\u001B[39m [torch\u001B[38;5;241m.\u001B[39mview_as_real(x) \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mis_complex(x) \u001B[38;5;28;01melse\u001B[39;00m x \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m device_exp_avgs]\n\u001B[1;32m    487\u001B[0m device_exp_avg_sqs \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    488\u001B[0m     torch\u001B[38;5;241m.\u001B[39mview_as_real(x) \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mis_complex(x) \u001B[38;5;28;01melse\u001B[39;00m x \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m device_exp_avg_sqs\n\u001B[1;32m    489\u001B[0m ]\n",
      "File \u001B[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/optim/adamw.py:485\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    481\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m maximize:\n\u001B[1;32m    482\u001B[0m     device_grads \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39m_foreach_neg(\u001B[38;5;28mtuple\u001B[39m(device_grads))  \u001B[38;5;66;03m# type: ignore[assignment]\u001B[39;00m\n\u001B[0;32m--> 485\u001B[0m device_grads \u001B[38;5;241m=\u001B[39m [torch\u001B[38;5;241m.\u001B[39mview_as_real(x) \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01melse\u001B[39;00m x \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m device_grads]\n\u001B[1;32m    486\u001B[0m device_exp_avgs \u001B[38;5;241m=\u001B[39m [torch\u001B[38;5;241m.\u001B[39mview_as_real(x) \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mis_complex(x) \u001B[38;5;28;01melse\u001B[39;00m x \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m device_exp_avgs]\n\u001B[1;32m    487\u001B[0m device_exp_avg_sqs \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    488\u001B[0m     torch\u001B[38;5;241m.\u001B[39mview_as_real(x) \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mis_complex(x) \u001B[38;5;28;01melse\u001B[39;00m x \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m device_exp_avg_sqs\n\u001B[1;32m    489\u001B[0m ]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch_num in range(1):\n",
    "    batches = tqdm.tqdm(list(range(0, len(token_ids), C_BATCH_SIZE)), desc=f'Epoch {epoch_num}', disable=False)\n",
    "    for batch_i in batches:\n",
    "        step_start_time = time.time()\n",
    "\n",
    "        inputs = token_ids[batch_i:batch_i + C_BATCH_SIZE, :-1]\n",
    "        labels = token_ids[batch_i:batch_i + C_BATCH_SIZE, 1:]\n",
    "        positions = position_ids[batch_i:batch_i + C_BATCH_SIZE, :-1]\n",
    "        masks = attn_mask[batch_i:batch_i + C_BATCH_SIZE, :-1]\n",
    "        # loss_masks = train_mask[batch_i:batch_i + C_BATCH_SIZE, 1:].to(model.device, C_DTYPE)\n",
    "\n",
    "        logits, _ = model.forward(inputs.to(model.device),\n",
    "                                  position_ids=positions.to(model.device),\n",
    "                                  attn_mask=masks.to(model.device)\n",
    "                                  )\n",
    "        probs = torch.softmax(logits, dim=2)  # BSZ * SEQ * VOCAB\n",
    "        probs_flat = probs.view(-1, C_VOCAB_SIZE)\n",
    "        #  * masks.reshape(-1)\n",
    "        loss = (-torch.log(probs_flat[torch.arange(probs_flat.shape[0]), labels.reshape(-1)])).mean()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        step_time_cost = time.time() - step_start_time\n",
    "        throughput = round((C_BATCH_SIZE * C_SEQ_LEN) / step_time_cost / 1000, 2)\n",
    "        batches.set_postfix({\n",
    "            'Loss': f'{loss.item():.3f}',\n",
    "            'LR': f'{scheduler.get_last_lr()[0]:.5}',\n",
    "            'Throughput': f'{throughput} kt/s'\n",
    "        })\n",
    "        # print({\n",
    "        #     'Loss': f'{loss.item():.3f}',\n",
    "        #     'LR': f'{scheduler.get_last_lr()[0]:.5}',\n",
    "        #     'Throughput': f'{throughput} kt/s'\n",
    "        # })\n",
    "        scheduler.step()\n",
    "    batches.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2e800403549c98d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T04:02:06.369328510Z",
     "start_time": "2023-10-11T04:02:06.364328369Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "\n",
    "def generate(tokenizer, prompt, temperature, top_p, rep_penalty, max_new_tokens=20, total_tokens=None, end_tokens=None, enable_kv_cache=True):\n",
    "    feed_tokens = tokenizer.encode(prompt)\n",
    "    all_tokens = feed_tokens.copy()\n",
    "    if total_tokens is not None:\n",
    "        max_new_tokens = max(0, total_tokens - len(feed_tokens))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        kv_cache = None\n",
    "        for _ in range(max_new_tokens):\n",
    "            position_ids = None if kv_cache is None else torch.tensor([[len(all_tokens) - 1]]).to(C_DEVICE)\n",
    "            logits, kv_cache = model.forward(torch.tensor([feed_tokens if enable_kv_cache else all_tokens]).to(C_DEVICE),\n",
    "                                             position_ids=position_ids,\n",
    "                                             kv_cache=kv_cache)\n",
    "            logits = logits[0][-1].cpu()\n",
    "            if not enable_kv_cache:\n",
    "                kv_cache = None\n",
    "\n",
    "            # apply repetition penalty\n",
    "            logits_rep = torch.gather(logits, 0, torch.tensor(all_tokens))\n",
    "            logits_rep = torch.where(logits_rep < 0, logits_rep * rep_penalty, logits_rep / rep_penalty)\n",
    "            logits.scatter_(0, torch.tensor(all_tokens), logits_rep)\n",
    "\n",
    "            # apply temperature\n",
    "            logits /= max(temperature, 1e-6)\n",
    "\n",
    "            probs = torch.softmax(logits, dim=0)\n",
    "\n",
    "            # apply top-p\n",
    "            ordered_probs, ordered_indices = torch.sort(probs, descending=True)\n",
    "            cum_probs = torch.cumsum(ordered_probs, dim=0).tolist()\n",
    "            top_p_index = bisect.bisect_right(cum_probs, top_p) + 1\n",
    "            ordered_probs, ordered_indices = ordered_probs[:top_p_index], ordered_indices[:top_p_index]\n",
    "            sampled_index = ordered_indices[torch.multinomial(ordered_probs, num_samples=1).item()].item()\n",
    "\n",
    "            all_tokens.append(sampled_index)\n",
    "            feed_tokens = [sampled_index]\n",
    "\n",
    "            if end_tokens is not None and sampled_index in end_tokens:\n",
    "                break\n",
    "    # print(tokens)\n",
    "    return tokenizer.decode(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "'<s>Once upon a time there was a little boy named Ben. Ben loved to explore the world around him. He saw many amazing things, like beautiful <unk> that were on display in a store. One day, Ben was walking through the store when he came across a very special vase. When Ben saw it he was amazed!  \\nHe said, “Wow, that is a really amazing vase! Can I buy it?” \\nThe shopkeeper smiled and said, “Of course you can. You can take it home and show all your friends how amazing it is!”\\nSo Ben took the vase home and he was so proud of it! He called his friends over and showed them the amazing vase. All his friends thought the vase was beautiful and couldn\\'t believe how lucky Ben was. \\nAnd that\\'s how Ben found an amazing vase in the store!</s><s>Once upon a time, there was a reliable otter named Ollie. He lived in a river with his family. They all loved to play and swim together.\\nOne day, Ollie\\'s mom said, \"Ollie, hurry and get some fish for dinner!\" Ollie swam fast to catch fish. He saw his friend, the duck. \"Hi, Ollie!\" said the duck. \"Hi, duck!\" said Ollie. \"I need to hurry and catch fish for my family.\"\\nWhile Ollie was catching fish, he found a big shiny stone. '"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(token_ids[0].tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T04:02:07.056166601Z",
     "start_time": "2023-10-11T04:02:07.054208010Z"
    }
   },
   "id": "f94c17f13926df4a"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.bfloat16"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder_layers[0].mha.attn_heads[0].dtype"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T04:02:07.468284541Z",
     "start_time": "2023-10-11T04:02:07.464875071Z"
    }
   },
   "id": "675a7b612752eaf3"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1bc924753b5acfc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T04:02:10.063873262Z",
     "start_time": "2023-10-11T04:02:08.314599757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Once upon the time, there was a little girl named Lily. She had a toy bear named Ben. Lily and Ben did everything together. They played, ate, and slept. One day, Lily's mom gave her a task. The task was to clean her room.\n",
      "Lily said, \"I will do it.\" She started to clean. She put away toys and clothes. But then, she saw a dead bug on the floor. She felt sad. Her mom came in and said, \"Don't worry, Lily.\"\n",
      "Lily learned that is not good for <unk>. She learns that can be by and help others. And they all need when you are good.</s>\n",
      "1.744 sec(s)\n"
     ]
    }
   ],
   "source": [
    "a = time.time()\n",
    "print(generate(tokenizer, '<s>Once upon the time',\n",
    "               temperature=1.0, top_p=0.001, rep_penalty=1.1,\n",
    "               total_tokens=512,\n",
    "               end_tokens=tokenizer.encode('</s>'),\n",
    "               enable_kv_cache=True))\n",
    "print(f'{time.time() - a:.3f} sec(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dfb4a3c8dcbb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(debug_seq[-1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191841b1a87d1069",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(torch.finfo(torch.bfloat16).min / 2, dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimizer.state_dict()['state'].keys()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a25faa06d3e1a9c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'tiny_stories_0.8_epoch.pt')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6b62aa4b37ffe30"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6aa5f8e290a1ccd3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = (torch.cuda.memory_snapshot())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c05e73f7f7c63f0f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x[0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de755042f3d20471"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def isTorchSubClass(obj):\n",
    "    for parent in obj.__class__.__mro__:\n",
    "        if parent.__module__.startswith(\"torch\"):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def findTensors(obj, objPath, results, depth):\n",
    "    if depth > 5 or obj == results:\n",
    "        return\n",
    "\n",
    "    if isinstance(obj, (list, tuple, set)):\n",
    "        for i, o in enumerate(obj):\n",
    "            findTensors(o, f\"{objPath}[{i}]\", results, depth + 1)\n",
    "    elif isinstance(obj, dict):\n",
    "        for k, v in obj.items():\n",
    "            findTensors(v, f\"{objPath}[{k}]\", results, depth + 1)\n",
    "\n",
    "    if type(obj) is torch.Tensor:\n",
    "        results.setdefault(objPath, obj)\n",
    "    elif isTorchSubClass(obj):\n",
    "        for attrName in dir(obj):\n",
    "            try:\n",
    "                findTensors(\n",
    "                    getattr(obj, attrName), f\"{objPath}.{attrName}\", results, depth + 1\n",
    "                )\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "def outputTensorSummary(deepTraverse=False):\n",
    "    from gc import get_objects\n",
    "    from warnings import filterwarnings\n",
    "    from collections import Counter\n",
    "\n",
    "    unit, unitName = 1024, \"KB\"\n",
    "\n",
    "    filterwarnings(\"ignore\", message=\"torch.distributed.reduce_op is deprecated\")\n",
    "\n",
    "    isTensor = lambda obj: isinstance(obj, torch.Tensor) or (\n",
    "            hasattr(obj, \"data\") and isinstance(obj.data, torch.Tensor)\n",
    "    )\n",
    "\n",
    "    if deepTraverse:\n",
    "        globalTensors = {}\n",
    "        findTensors(globals().copy(), \"Global\", globalTensors, 0)\n",
    "        globalTensors = {id(v): k for k, v in globalTensors.items()}\n",
    "    else:\n",
    "        globalTensors = {id(v): k for k, v in globals().items() if isTensor(v)}\n",
    "\n",
    "    totalUsage = 0\n",
    "    trivialMemoryUsage = 0\n",
    "    bigTensors = []\n",
    "    for obj in get_objects():\n",
    "        try:\n",
    "            if isTensor(obj):\n",
    "                if obj.device.index == None:\n",
    "                    continue\n",
    "                tensorMemSize = obj.nelement() * obj.element_size()\n",
    "                totalUsage += tensorMemSize\n",
    "                if (tensorMemSize / unit) < 1:\n",
    "                    trivialMemoryUsage += tensorMemSize\n",
    "                    continue\n",
    "                if id(obj) in globalTensors:\n",
    "                    bigTensors.append(\n",
    "                        (obj.shape, tensorMemSize / unit, globalTensors[id(obj)])\n",
    "                    )\n",
    "                else:\n",
    "                    bigTensors.append((obj.shape, tensorMemSize / unit))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    print(f\"Total {totalUsage / unit:.2f} {unitName} CUDA memory in use.\\n\")\n",
    "\n",
    "    bigTensors.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    maxLowerUnit, minLowerUnit = 1000, 100\n",
    "    while minLowerUnit >= 1:\n",
    "        inRangeTensors = [t for t in bigTensors if minLowerUnit <= t[1] <= maxLowerUnit]\n",
    "        groupCounter = Counter(inRangeTensors)\n",
    "        print(f\"Tensors of size {minLowerUnit:>5} - {maxLowerUnit:>5} {unitName}:\")\n",
    "        for tensor, count in groupCounter.items():\n",
    "            print(\n",
    "                f\"  {count:4} * Size: {tensor[1]:.2f} {unitName} Shape: {[*tensor[0]]}\",\n",
    "                end=\"\",\n",
    "            )\n",
    "            print(f' {tensor[2]:.30}' if len(tensor) == 3 else \"\")\n",
    "\n",
    "        print(f\"Total: {sum([t[1] for t in inRangeTensors]):.2f} {unitName}\\n\")\n",
    "        maxLowerUnit, minLowerUnit = maxLowerUnit // 10, minLowerUnit // 10\n",
    "\n",
    "    print(\n",
    "        f\"Total {trivialMemoryUsage / unit :.2f} {unitName} is occupied by trivial tensors(<=1{unitName}).\"\n",
    "    )\n",
    "\n",
    "\n",
    "outputTensorSummary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28cf9c6e7de51317"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T03:56:32.929257629Z",
     "start_time": "2023-10-11T03:56:32.918209238Z"
    }
   },
   "id": "3f76f81f024ab03d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9cf1d9368279ed9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
